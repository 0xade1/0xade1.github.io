{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjO7bdcb3XAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ed9b6373-a55f-4457-c5c1-4425dfd8941a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJNYnUcv7V6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10d5a14d-00a5-4caf-9db6-11f64041afe3"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "print(device_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ed3XjgJ1oLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8eb4344c-e082-4c87-d28f-663c5bb70a1a"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Fridosleigh.com CAPTEHA API - Made by Krampus Hollyfeld\n",
        "%tensorflow_version 1.15\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "import requests\n",
        "import json\n",
        "import sys\n",
        "import numpy as np\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import csv\n",
        "\n",
        "# sudo apt install python3-pip\n",
        "# sudo python3 -m pip install --upgrade pip\n",
        "# sudo python3 -m pip install --upgrade setuptools\n",
        "# sudo python3 -m pip install --upgrade tensorflow==1.15\n",
        "\n",
        "def load_labels(label_file):\n",
        "    label = []\n",
        "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
        "    for l in proto_as_ascii_lines:\n",
        "        label.append(l.rstrip())\n",
        "    return label\n",
        "\n",
        "def load_graph(model_file):\n",
        "    graph = tf.Graph()\n",
        "    graph_def = tf.GraphDef()\n",
        "    with open(model_file, \"rb\") as f:\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    with graph.as_default():\n",
        "        tf.import_graph_def(graph_def)\n",
        "    return graph\n",
        "\n",
        "def read_tensor_from_image_bytes(imagebytes, input_height=299, input_width=299, input_mean=0, input_std=255):\n",
        "    image_reader = tf.image.decode_png( imagebytes, channels=3, name=\"png_reader\")\n",
        "    float_caster = tf.cast(image_reader, tf.float32)\n",
        "    dims_expander = tf.expand_dims(float_caster, 0)\n",
        "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
        "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
        "    sess = tf.compat.v1.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
        "    result = sess.run(normalized)\n",
        "    return result\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9XRSKnE7r4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_image_cpu(q, sess, graph, image_bytes, uuid, labels, input_operation, output_operation):\n",
        "  with tf.device('/cpu:0'): \n",
        "    image = read_tensor_from_image_bytes(image_bytes)\n",
        "    results = sess.run(output_operation.outputs[0], {\n",
        "        input_operation.outputs[0]: image\n",
        "    })\n",
        "    results = np.squeeze(results)\n",
        "    prediction = results.argsort()[-5:][::-1][0]\n",
        "    q.put( {'uuid':uuid, 'prediction':labels[prediction].title(), 'percent':results[prediction]} )\n",
        "\n",
        "def predict_image_gpu(q, sess, graph, image_bytes, uuid, labels, input_operation, output_operation):\n",
        "  #with tf.device('/gpu:0'): \n",
        "    image = read_tensor_from_image_bytes(image_bytes)\n",
        "    results = sess.run(output_operation.outputs[0], {\n",
        "        input_operation.outputs[0]: image\n",
        "    })\n",
        "    results = np.squeeze(results)\n",
        "    prediction = results.argsort()[-5:][::-1][0]\n",
        "    q.put( {'uuid':uuid, 'prediction':labels[prediction].title(), 'percent':results[prediction]} )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFm3YfAL7_qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e8f9f3b-f32f-4232-b6a0-e49192603ab4"
      },
      "source": [
        "    #This list should contains only uuids predicted by our ML model to match the challenge_image_type\n",
        "    b64_images_match = []\n",
        "\n",
        "    # Loading the Trained Machine Learning Model created from running retrain.py on the training_images directory\n",
        "    graph = load_graph('/content/drive/My Drive/TensorFlow_model/tmp/retrain_tmp/output_graph.pb')\n",
        "    labels = load_labels(\"//content/drive/My Drive/TensorFlow_model/tmp/retrain_tmp/output_labels.txt\")\n",
        "\n",
        "    # Load up our session\n",
        "    input_operation = graph.get_operation_by_name(\"import/Placeholder\")\n",
        "    output_operation = graph.get_operation_by_name(\"import/final_result\")\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      sess = tf.compat.v1.Session(graph=graph, config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
        "\n",
        "    # Can use queues and threading to spead up the processing\n",
        "    q = queue.Queue()\n",
        "\n",
        "    \n",
        "    '''\n",
        "    REQUESTING\n",
        "    '''\n",
        "    yourREALemailAddress = \"0xade1@yopmail.com\"\n",
        "\n",
        "    # Creating a session to handle cookies\n",
        "    s = requests.Session()\n",
        "    url = \"https://fridosleigh.com/\"\n",
        "\n",
        "    json_resp = json.loads(s.get(\"{}api/capteha/request\".format(url)).text)\n",
        "    b64_images = json_resp['images']                    # A list of dictionaries eaching containing the keys 'base64' and 'uuid'\n",
        "    challenge_image_type = json_resp['select_type'].split(',')     # The Image types the CAPTEHA Challenge is looking for.\n",
        "    challenge_image_types = [challenge_image_type[0].strip(), challenge_image_type[1].strip(), challenge_image_type[2].replace(' and ','').strip()] # cleaning and formatting\n",
        "\n",
        "    '''\n",
        "    MISSING IMAGE PROCESSING AND ML IMAGE PREDICTION CODE GOES HERE\n",
        "    '''\n",
        "    import base64\n",
        "\n",
        "    #challenge_image_types = [i.replace(' ','_') for i in challenge_image_types]\n",
        "\n",
        "    queue_size = len(b64_images)\n",
        "    for img in b64_images:\n",
        "        #convert base64 representation of image into bytes\n",
        "        uuid = img['uuid']\n",
        "        image_bytes = base64.b64decode(img['base64'])\n",
        "        #Classify the image type using our ML Image recognition model\n",
        "        #predict_image_gpu(q, sess, graph, image_bytes, uuid, labels, input_operation, output_operation)\n",
        "        threading.Thread(target=predict_image_gpu, args=(q, sess, graph, image_bytes, uuid, labels, input_operation, output_operation)).start()\n",
        "\n",
        "    print('Waiting For Threads to Finish...')\n",
        "    while q.qsize() < queue_size:\n",
        "       time.sleep(0.001)\n",
        "\n",
        "    #getting a list of all threads returned results\n",
        "    prediction_results = [q.get() for x in range(q.qsize())]\n",
        "\n",
        "    #do something with our results... Like print them to the screen.\n",
        "    for prediction in prediction_results:\n",
        "        print('TensorFlow Predicted {uuid} is a {prediction} with {percent:.2%} Accuracy'.format(**prediction))\n",
        "        img_type = '{prediction}'.format(**prediction)\n",
        "        if img_type in challenge_image_types:\n",
        "            b64_images_match.append('{uuid}'.format(**prediction))\n",
        "\n",
        "    # This should be JUST a csv list image uuids ML predicted to match the challenge_image_type .\n",
        "    #final_answer = ','.join( [ img['uuid'] for img in b64_images_match ] )\n",
        "    final_answer = ','.join(b64_images_match)\n",
        "\n",
        "    #print(final_answer)\n",
        "\n",
        "    '''\n",
        "    END OF CUSTOM CODE\n",
        "    '''\n",
        "\n",
        "    json_resp = json.loads(s.post(\"{}api/capteha/submit\".format(url), data={'answer':final_answer}).text)\n",
        "    if not json_resp['request']:\n",
        "        # If it fails just run again. ML might get one wrong occasionally\n",
        "        print('FAILED MACHINE LEARNING GUESS')\n",
        "        print('--------------------\\nOur ML Guess:\\n--------------------\\n{}'.format(final_answer))\n",
        "        print('--------------------\\nServer Response:\\n--------------------\\n{}'.format(json_resp['data']))\n",
        "        sys.exit(1)\n",
        "\n",
        "    print('CAPTEHA Solved!')\n",
        "    # If we get to here, we are successful and can submit a bunch of entries till we win\n",
        "    userinfo = {\n",
        "        'name':'Krampus Hollyfeld',\n",
        "        'email':yourREALemailAddress,\n",
        "        'age':180,\n",
        "        'about':\"Cause they're so flippin yummy!\",\n",
        "        'favorites':'thickmints'\n",
        "    }\n",
        "    # If we win the once-per minute drawing, it will tell us we were emailed.\n",
        "    # Should be no more than 200 times before we win. If more, somethings wrong.\n",
        "    entry_response = ''\n",
        "    entry_count = 1\n",
        "    while yourREALemailAddress not in entry_response and entry_count < 200:\n",
        "        print('Submitting lots of entries until we win the contest! Entry #{}'.format(entry_count))\n",
        "        entry_response = s.post(\"{}api/entry\".format(url), data=userinfo).text\n",
        "        entry_count += 1\n",
        "    print(entry_response)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Waiting For Threads to Finish...\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n",
            "TensorFlow Predicted cc28be4a-e584-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.88% Accuracy\n",
            "TensorFlow Predicted 61628b3d-e586-11e9-97c1-309c23aaf0ac is a Stockings with 95.95% Accuracy\n",
            "TensorFlow Predicted cf47cb9d-e584-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.85% Accuracy\n",
            "TensorFlow Predicted f4c6edc5-e585-11e9-97c1-309c23aaf0ac is a Stockings with 99.87% Accuracy\n",
            "TensorFlow Predicted f96a489a-e584-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.49% Accuracy\n",
            "TensorFlow Predicted 30d68eed-e585-11e9-97c1-309c23aaf0ac is a Ornaments with 99.93% Accuracy\n",
            "TensorFlow Predicted a9dfd505-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.52% Accuracy\n",
            "TensorFlow Predicted 08e7a741-e585-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.97% Accuracy\n",
            "TensorFlow Predicted fd479305-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.85% Accuracy\n",
            "TensorFlow Predicted 729cb0c4-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.92% Accuracy\n",
            "TensorFlow Predicted 0374013f-e586-11e9-97c1-309c23aaf0ac is a Ornaments with 98.81% Accuracy\n",
            "TensorFlow Predicted c528d85c-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 98.93% Accuracy\n",
            "TensorFlow Predicted 27bf8128-e585-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.77% Accuracy\n",
            "TensorFlow Predicted 78675068-e585-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.91% Accuracy\n",
            "TensorFlow Predicted b0984bd1-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.99% Accuracy\n",
            "TensorFlow Predicted 0355a40c-e586-11e9-97c1-309c23aaf0ac is a Presents with 98.68% Accuracy\n",
            "TensorFlow Predicted f04bb9db-e584-11e9-97c1-309c23aaf0ac is a Stockings with 99.99% Accuracy\n",
            "TensorFlow Predicted a56779a5-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.98% Accuracy\n",
            "TensorFlow Predicted 3b54d7a6-e586-11e9-97c1-309c23aaf0ac is a Stockings with 98.53% Accuracy\n",
            "TensorFlow Predicted 08e2dbad-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.81% Accuracy\n",
            "TensorFlow Predicted 042154f3-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.97% Accuracy\n",
            "TensorFlow Predicted 0080bc39-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.76% Accuracy\n",
            "TensorFlow Predicted 5471b14b-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.98% Accuracy\n",
            "TensorFlow Predicted 57cb2ffa-e585-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.87% Accuracy\n",
            "TensorFlow Predicted a6accc21-e585-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.96% Accuracy\n",
            "TensorFlow Predicted 7e089fc7-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.87% Accuracy\n",
            "TensorFlow Predicted 722e9cf9-e586-11e9-97c1-309c23aaf0ac is a Presents with 99.99% Accuracy\n",
            "TensorFlow Predicted ef69564b-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.94% Accuracy\n",
            "TensorFlow Predicted 2e062dd7-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.51% Accuracy\n",
            "TensorFlow Predicted 779f5a62-e586-11e9-97c1-309c23aaf0ac is a Presents with 99.88% Accuracy\n",
            "TensorFlow Predicted 565675de-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.98% Accuracy\n",
            "TensorFlow Predicted 94568df6-e587-11e9-97c1-309c23aaf0ac is a Ornaments with 99.37% Accuracy\n",
            "TensorFlow Predicted 4f147f07-e585-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.59% Accuracy\n",
            "TensorFlow Predicted b6c49036-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.87% Accuracy\n",
            "TensorFlow Predicted bfcde9cc-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.97% Accuracy\n",
            "TensorFlow Predicted fd63e782-e587-11e9-97c1-309c23aaf0ac is a Stockings with 99.93% Accuracy\n",
            "TensorFlow Predicted 1101a8c1-e588-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.93% Accuracy\n",
            "TensorFlow Predicted 86ae8243-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.98% Accuracy\n",
            "TensorFlow Predicted 3ec3c1e7-e588-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.90% Accuracy\n",
            "TensorFlow Predicted 5d698cfd-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.44% Accuracy\n",
            "TensorFlow Predicted 4abe99cc-e588-11e9-97c1-309c23aaf0ac is a Stockings with 99.93% Accuracy\n",
            "TensorFlow Predicted ee36dbdf-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.56% Accuracy\n",
            "TensorFlow Predicted 05c88fa7-e588-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.89% Accuracy\n",
            "TensorFlow Predicted b5d18774-e587-11e9-97c1-309c23aaf0ac is a Presents with 99.94% Accuracy\n",
            "TensorFlow Predicted 25ffad29-e588-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.96% Accuracy\n",
            "TensorFlow Predicted ca77ef0b-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.60% Accuracy\n",
            "TensorFlow Predicted cb98b598-e587-11e9-97c1-309c23aaf0ac is a Stockings with 99.63% Accuracy\n",
            "TensorFlow Predicted f4774d66-e587-11e9-97c1-309c23aaf0ac is a Ornaments with 99.70% Accuracy\n",
            "TensorFlow Predicted fde3c7bb-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.89% Accuracy\n",
            "TensorFlow Predicted 5eaec909-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.57% Accuracy\n",
            "TensorFlow Predicted 2db6433e-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.62% Accuracy\n",
            "TensorFlow Predicted 2efa293f-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.82% Accuracy\n",
            "TensorFlow Predicted 87c03ac0-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.92% Accuracy\n",
            "TensorFlow Predicted 1098f968-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.83% Accuracy\n",
            "TensorFlow Predicted 9c7017d8-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.93% Accuracy\n",
            "TensorFlow Predicted da1cee93-e584-11e9-97c1-309c23aaf0ac is a Ornaments with 99.91% Accuracy\n",
            "TensorFlow Predicted 852f4642-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.87% Accuracy\n",
            "TensorFlow Predicted 1b2d5c68-e586-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.99% Accuracy\n",
            "TensorFlow Predicted 27dd6329-e586-11e9-97c1-309c23aaf0ac is a Stockings with 98.84% Accuracy\n",
            "TensorFlow Predicted b7399056-e585-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.93% Accuracy\n",
            "TensorFlow Predicted 61799087-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.75% Accuracy\n",
            "TensorFlow Predicted 824105c5-e585-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.37% Accuracy\n",
            "TensorFlow Predicted b8d628d6-e585-11e9-97c1-309c23aaf0ac is a Stockings with 98.60% Accuracy\n",
            "TensorFlow Predicted 2a272315-e585-11e9-97c1-309c23aaf0ac is a Stockings with 99.85% Accuracy\n",
            "TensorFlow Predicted 91dcd77a-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.92% Accuracy\n",
            "TensorFlow Predicted ec40524f-e584-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.73% Accuracy\n",
            "TensorFlow Predicted ff8718fc-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.54% Accuracy\n",
            "TensorFlow Predicted d6679984-e584-11e9-97c1-309c23aaf0ac is a Stockings with 95.31% Accuracy\n",
            "TensorFlow Predicted a7d6c1a1-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.93% Accuracy\n",
            "TensorFlow Predicted 4c9325e4-e585-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.73% Accuracy\n",
            "TensorFlow Predicted d1521716-e586-11e9-97c1-309c23aaf0ac is a Presents with 96.37% Accuracy\n",
            "TensorFlow Predicted e25eea4a-e585-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.83% Accuracy\n",
            "TensorFlow Predicted 62e0ffb0-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.94% Accuracy\n",
            "TensorFlow Predicted 219c664b-e587-11e9-97c1-309c23aaf0ac is a Presents with 99.18% Accuracy\n",
            "TensorFlow Predicted b7230c24-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.23% Accuracy\n",
            "TensorFlow Predicted 6fc5146e-e585-11e9-97c1-309c23aaf0ac is a Ornaments with 99.61% Accuracy\n",
            "TensorFlow Predicted 98a5d7ef-e585-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.76% Accuracy\n",
            "TensorFlow Predicted 11983311-e587-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.99% Accuracy\n",
            "TensorFlow Predicted b2fe4c4e-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.95% Accuracy\n",
            "TensorFlow Predicted f5ea450c-e586-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.66% Accuracy\n",
            "TensorFlow Predicted 3675b985-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.86% Accuracy\n",
            "TensorFlow Predicted 09b697f9-e586-11e9-97c1-309c23aaf0ac is a Santa Hats with 98.97% Accuracy\n",
            "TensorFlow Predicted ecf27f99-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.82% Accuracy\n",
            "TensorFlow Predicted 4f16112a-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.91% Accuracy\n",
            "TensorFlow Predicted e9eb5ce3-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.97% Accuracy\n",
            "TensorFlow Predicted 487ce4d6-e587-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.61% Accuracy\n",
            "TensorFlow Predicted 4663abc9-e586-11e9-97c1-309c23aaf0ac is a Stockings with 99.88% Accuracy\n",
            "TensorFlow Predicted be34e29e-e584-11e9-97c1-309c23aaf0ac is a Candy Canes with 99.54% Accuracy\n",
            "TensorFlow Predicted 8342290b-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.83% Accuracy\n",
            "TensorFlow Predicted c0554cc1-e584-11e9-97c1-309c23aaf0ac is a Stockings with 99.87% Accuracy\n",
            "TensorFlow Predicted 80484139-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.83% Accuracy\n",
            "TensorFlow Predicted 37c17411-e588-11e9-97c1-309c23aaf0ac is a Stockings with 99.97% Accuracy\n",
            "TensorFlow Predicted 8455e3c2-e587-11e9-97c1-309c23aaf0ac is a Stockings with 97.83% Accuracy\n",
            "TensorFlow Predicted 9026929e-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 98.98% Accuracy\n",
            "TensorFlow Predicted 156eabd3-e588-11e9-97c1-309c23aaf0ac is a Stockings with 99.96% Accuracy\n",
            "TensorFlow Predicted ebed99b9-e587-11e9-97c1-309c23aaf0ac is a Stockings with 99.70% Accuracy\n",
            "TensorFlow Predicted 1797aa44-e588-11e9-97c1-309c23aaf0ac is a Santa Hats with 99.71% Accuracy\n",
            "TensorFlow Predicted 35dd8fe2-e585-11e9-97c1-309c23aaf0ac is a Stockings with 93.04% Accuracy\n",
            "TensorFlow Predicted c1ed2829-e587-11e9-97c1-309c23aaf0ac is a Stockings with 99.90% Accuracy\n",
            "TensorFlow Predicted e58c1563-e587-11e9-97c1-309c23aaf0ac is a Christmas Trees with 99.72% Accuracy\n",
            "CAPTEHA Solved!\n",
            "Submitting lots of entries until we win the contest! Entry #1\n",
            "Submitting lots of entries until we win the contest! Entry #2\n",
            "Submitting lots of entries until we win the contest! Entry #3\n",
            "Submitting lots of entries until we win the contest! Entry #4\n",
            "Submitting lots of entries until we win the contest! Entry #5\n",
            "Submitting lots of entries until we win the contest! Entry #6\n",
            "Submitting lots of entries until we win the contest! Entry #7\n",
            "Submitting lots of entries until we win the contest! Entry #8\n",
            "Submitting lots of entries until we win the contest! Entry #9\n",
            "Submitting lots of entries until we win the contest! Entry #10\n",
            "Submitting lots of entries until we win the contest! Entry #11\n",
            "Submitting lots of entries until we win the contest! Entry #12\n",
            "Submitting lots of entries until we win the contest! Entry #13\n",
            "Submitting lots of entries until we win the contest! Entry #14\n",
            "Submitting lots of entries until we win the contest! Entry #15\n",
            "Submitting lots of entries until we win the contest! Entry #16\n",
            "Submitting lots of entries until we win the contest! Entry #17\n",
            "Submitting lots of entries until we win the contest! Entry #18\n",
            "Submitting lots of entries until we win the contest! Entry #19\n",
            "Submitting lots of entries until we win the contest! Entry #20\n",
            "Submitting lots of entries until we win the contest! Entry #21\n",
            "Submitting lots of entries until we win the contest! Entry #22\n",
            "Submitting lots of entries until we win the contest! Entry #23\n",
            "Submitting lots of entries until we win the contest! Entry #24\n",
            "Submitting lots of entries until we win the contest! Entry #25\n",
            "Submitting lots of entries until we win the contest! Entry #26\n",
            "Submitting lots of entries until we win the contest! Entry #27\n",
            "Submitting lots of entries until we win the contest! Entry #28\n",
            "Submitting lots of entries until we win the contest! Entry #29\n",
            "Submitting lots of entries until we win the contest! Entry #30\n",
            "Submitting lots of entries until we win the contest! Entry #31\n",
            "Submitting lots of entries until we win the contest! Entry #32\n",
            "Submitting lots of entries until we win the contest! Entry #33\n",
            "Submitting lots of entries until we win the contest! Entry #34\n",
            "Submitting lots of entries until we win the contest! Entry #35\n",
            "Submitting lots of entries until we win the contest! Entry #36\n",
            "Submitting lots of entries until we win the contest! Entry #37\n",
            "Submitting lots of entries until we win the contest! Entry #38\n",
            "Submitting lots of entries until we win the contest! Entry #39\n",
            "Submitting lots of entries until we win the contest! Entry #40\n",
            "Submitting lots of entries until we win the contest! Entry #41\n",
            "Submitting lots of entries until we win the contest! Entry #42\n",
            "Submitting lots of entries until we win the contest! Entry #43\n",
            "Submitting lots of entries until we win the contest! Entry #44\n",
            "Submitting lots of entries until we win the contest! Entry #45\n",
            "Submitting lots of entries until we win the contest! Entry #46\n",
            "Submitting lots of entries until we win the contest! Entry #47\n",
            "Submitting lots of entries until we win the contest! Entry #48\n",
            "Submitting lots of entries until we win the contest! Entry #49\n",
            "Submitting lots of entries until we win the contest! Entry #50\n",
            "Submitting lots of entries until we win the contest! Entry #51\n",
            "Submitting lots of entries until we win the contest! Entry #52\n",
            "Submitting lots of entries until we win the contest! Entry #53\n",
            "Submitting lots of entries until we win the contest! Entry #54\n",
            "Submitting lots of entries until we win the contest! Entry #55\n",
            "Submitting lots of entries until we win the contest! Entry #56\n",
            "Submitting lots of entries until we win the contest! Entry #57\n",
            "Submitting lots of entries until we win the contest! Entry #58\n",
            "Submitting lots of entries until we win the contest! Entry #59\n",
            "Submitting lots of entries until we win the contest! Entry #60\n",
            "Submitting lots of entries until we win the contest! Entry #61\n",
            "Submitting lots of entries until we win the contest! Entry #62\n",
            "Submitting lots of entries until we win the contest! Entry #63\n",
            "Submitting lots of entries until we win the contest! Entry #64\n",
            "Submitting lots of entries until we win the contest! Entry #65\n",
            "Submitting lots of entries until we win the contest! Entry #66\n",
            "Submitting lots of entries until we win the contest! Entry #67\n",
            "Submitting lots of entries until we win the contest! Entry #68\n",
            "Submitting lots of entries until we win the contest! Entry #69\n",
            "Submitting lots of entries until we win the contest! Entry #70\n",
            "Submitting lots of entries until we win the contest! Entry #71\n",
            "Submitting lots of entries until we win the contest! Entry #72\n",
            "Submitting lots of entries until we win the contest! Entry #73\n",
            "Submitting lots of entries until we win the contest! Entry #74\n",
            "Submitting lots of entries until we win the contest! Entry #75\n",
            "Submitting lots of entries until we win the contest! Entry #76\n",
            "Submitting lots of entries until we win the contest! Entry #77\n",
            "Submitting lots of entries until we win the contest! Entry #78\n",
            "Submitting lots of entries until we win the contest! Entry #79\n",
            "Submitting lots of entries until we win the contest! Entry #80\n",
            "Submitting lots of entries until we win the contest! Entry #81\n",
            "Submitting lots of entries until we win the contest! Entry #82\n",
            "Submitting lots of entries until we win the contest! Entry #83\n",
            "Submitting lots of entries until we win the contest! Entry #84\n",
            "Submitting lots of entries until we win the contest! Entry #85\n",
            "Submitting lots of entries until we win the contest! Entry #86\n",
            "Submitting lots of entries until we win the contest! Entry #87\n",
            "Submitting lots of entries until we win the contest! Entry #88\n",
            "Submitting lots of entries until we win the contest! Entry #89\n",
            "Submitting lots of entries until we win the contest! Entry #90\n",
            "Submitting lots of entries until we win the contest! Entry #91\n",
            "Submitting lots of entries until we win the contest! Entry #92\n",
            "Submitting lots of entries until we win the contest! Entry #93\n",
            "Submitting lots of entries until we win the contest! Entry #94\n",
            "Submitting lots of entries until we win the contest! Entry #95\n",
            "Submitting lots of entries until we win the contest! Entry #96\n",
            "Submitting lots of entries until we win the contest! Entry #97\n",
            "Submitting lots of entries until we win the contest! Entry #98\n",
            "Submitting lots of entries until we win the contest! Entry #99\n",
            "Submitting lots of entries until we win the contest! Entry #100\n",
            "{\"data\":\"<h2 id=\\\"result_header\\\"> Entries for email address 0xade1@yopmail.com no longer accepted as our systems show your email was already randomly selected as a winner! Go check your email to get your winning code. Please allow up to 3-5 minutes for the email to arrive in your inbox or check your spam filter settings. <br><br> Congratulations and Happy Holidays!</h2>\",\"request\":true}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
